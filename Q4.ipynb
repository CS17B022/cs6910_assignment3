{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport random\nimport wandb\nfrom Levenshtein import distance\nimport plotly.graph_objects as go\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import TensorDataset\n\nimport time\nimport math\nimport argparse\nfrom types import SimpleNamespace\nfrom copy import deepcopy\n# functions with comments explained in script file\n# no redundant comments here\n# only new functions are explained here in comments","metadata":{"execution":{"iopub.status.busy":"2023-05-23T11:44:11.397878Z","iopub.execute_input":"2023-05-23T11:44:11.398436Z","iopub.status.idle":"2023-05-23T11:44:11.406818Z","shell.execute_reply.started":"2023-05-23T11:44:11.398403Z","shell.execute_reply":"2023-05-23T11:44:11.405907Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device = \", device)\n\n# Paste your own key\nwandb.login()\n\nSOS_token = \"@\"\nEOS_token = \"#\"\nPAD_token = \"^\"\nUNK_token = \"$\"\n\nSOS_idx = 0\nEOS_idx = 1\nPAD_idx = 2\nUNK_idx = 3\n\nbatch_size = 32\nlanguages = [\"asm\", \"ben\", \"brx\", \"guj\", \"hin\", \"kan\", \"kas\", \"kok\", \"mai\", \"mal\", \"mar\", \"mni\", \"ori\", \"pan\", \"san\", \"sid\", \"tam\", \"tel\", \"urd\"]\nbest_model_path = '/kaggle/working/best_model_vanilla.pth'\ntest_pred_path = '/kaggle/working/pred_vanilla.csv'","metadata":{"execution":{"iopub.status.busy":"2023-05-23T11:45:30.518662Z","iopub.execute_input":"2023-05-23T11:45:30.519272Z","iopub.status.idle":"2023-05-23T11:45:34.361074Z","shell.execute_reply.started":"2023-05-23T11:45:30.519230Z","shell.execute_reply":"2023-05-23T11:45:34.360120Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Device =  cuda\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}]},{"cell_type":"code","source":"def timeInMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    s = format(s, \".0f\")\n    return str(m) + \"m \" + str(s) + \"s\"","metadata":{"execution":{"iopub.status.busy":"2023-05-23T11:45:39.289829Z","iopub.execute_input":"2023-05-23T11:45:39.290177Z","iopub.status.idle":"2023-05-23T11:45:39.297114Z","shell.execute_reply.started":"2023-05-23T11:45:39.290148Z","shell.execute_reply":"2023-05-23T11:45:39.296189Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"class Script:\n    def __init__(self, name):\n        self.name = name\n        self.char2index = {SOS_token: SOS_idx, EOS_token: EOS_idx, PAD_token: PAD_idx, UNK_token: UNK_idx}\n        self.char2count = {}\n        self.index2char = {SOS_idx: SOS_token, EOS_idx: EOS_token, PAD_idx: PAD_token, UNK_idx: UNK_token}\n        self.n_chars = 4  # Count SOS, EOS, PAD and UNK\n\n    def addWord(self, word):\n        for char in word:\n            self.addChar(char)\n\n    def addChar(self, char):\n        if char not in self.char2index:\n            self.char2index[char] = self.n_chars\n            self.char2count[char] = 1\n            self.index2char[self.n_chars] = char\n            self.n_chars += 1\n        else:\n            self.char2count[char] += 1","metadata":{"execution":{"iopub.status.busy":"2023-05-23T11:45:39.877874Z","iopub.execute_input":"2023-05-23T11:45:39.880906Z","iopub.status.idle":"2023-05-23T11:45:39.889230Z","shell.execute_reply.started":"2023-05-23T11:45:39.880871Z","shell.execute_reply":"2023-05-23T11:45:39.888351Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"def prepareVocab(data, in_scr=\"lat\", out_scr=\"dev\"):\n    input_vocab = Script(in_scr)\n    output_vocab = Script(out_scr)\n    \n    for pair in data:\n        input_vocab.addWord(pair[0])\n        output_vocab.addWord(pair[1])\n    \n    return input_vocab, output_vocab\n\ndef tensorFromWord(word, vocab, sos=False, eos=False):\n    char_list = []\n    if sos:\n        char_list.append(vocab.char2index[SOS_token])\n    for char in word:\n        if char in vocab.char2index:\n            char_list.append(vocab.char2index[char])\n        else:\n            char_list.append(vocab.char2index[UNK_token])\n    if eos:\n        char_list.append(vocab.char2index[EOS_token])\n    char_tensor = torch.tensor(char_list, dtype=torch.long)\n    return char_tensor\n\ndef processData(data, vocab, sos=False, eos=False):\n    tensor_list = []\n    for word in data:\n        word_tensor = tensorFromWord(word, vocab, sos, eos)\n        tensor_list.append(word_tensor)\n    word_tensor_pad = pad_sequence(tensor_list, padding_value=PAD_idx, batch_first=True)\n    return word_tensor_pad\n\ndef wordFromTensor(word_tensor, vocab):\n    word = \"\"\n    for idx in word_tensor:\n        if idx == EOS_idx:\n            break\n        if idx >= UNK_idx:\n            word += vocab.index2char[idx.item()]\n    return word","metadata":{"execution":{"iopub.status.busy":"2023-05-23T11:45:40.933395Z","iopub.execute_input":"2023-05-23T11:45:40.933742Z","iopub.status.idle":"2023-05-23T11:45:40.943870Z","shell.execute_reply.started":"2023-05-23T11:45:40.933713Z","shell.execute_reply":"2023-05-23T11:45:40.942901Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, cell_type, input_size, embedding_size, hidden_size, num_layers, dp, bidir=False):\n        super(Encoder, self).__init__()\n        self.cell_type = cell_type\n        self.input_size = input_size\n        self.embedding_size = embedding_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.dropout = nn.Dropout(dp)\n        self.bidir = bidir\n        \n        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n        if self.num_layers == 1:\n            dp = 0.0\n        if self.cell_type == \"RNN\":\n            self.cell = nn.RNN(self.embedding_size, self.hidden_size, self.num_layers, dropout=dp, bidirectional=self.bidir)\n        elif self.cell_type == \"GRU\":\n            self.cell = nn.GRU(self.embedding_size, self.hidden_size, self.num_layers, dropout=dp, bidirectional=self.bidir)\n        elif self.cell_type == \"LSTM\":\n            self.cell = nn.LSTM(self.embedding_size, self.hidden_size, self.num_layers, dropout=dp, bidirectional=self.bidir)\n\n    def forward(self, x):\n\n        embedding = self.dropout(self.embedding(x))\n        \n        \n        cell = None\n        if self.cell_type == \"LSTM\":\n            outputs, (hidden, cell) = self.cell(embedding)\n            if self.bidir:\n                b_sz = cell.size(1)\n                cell = cell.view(self.num_layers, 2, b_sz, -1)\n                cell = cell[-1]\n                cell = cell.mean(axis=0)\n            else:\n                cell = cell[-1,:,:]\n            cell = cell.unsqueeze(0)\n        else:\n            outputs, hidden = self.cell(embedding)\n        \n        if self.bidir:\n            b_sz = hidden.size(1)\n            hidden = hidden.view(self.num_layers, 2, b_sz, -1)\n            hidden = hidden[-1]\n            hidden = hidden.mean(axis=0)\n        else:\n            hidden = hidden[-1,:,:]\n        hidden = hidden.unsqueeze(0)\n        \n\n        return hidden, cell","metadata":{"execution":{"iopub.status.busy":"2023-05-23T11:45:41.463122Z","iopub.execute_input":"2023-05-23T11:45:41.463791Z","iopub.status.idle":"2023-05-23T11:45:41.476463Z","shell.execute_reply.started":"2023-05-23T11:45:41.463755Z","shell.execute_reply":"2023-05-23T11:45:41.475499Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(\n        self, cell_type, input_size, embedding_size, hidden_size, output_size, num_layers, dp\n    ):\n        super(Decoder, self).__init__()\n        self.cell_type = cell_type\n        self.input_size = input_size\n        self.embedding_size = embedding_size\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.num_layers = num_layers\n        self.dropout = nn.Dropout(dp)\n\n        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n        if self.num_layers == 1:\n            dp = 0.0\n        if self.cell_type == \"RNN\":\n            self.cell = nn.RNN(self.embedding_size, self.hidden_size, self.num_layers, dropout=dp)\n        elif self.cell_type == \"GRU\":\n            self.cell = nn.GRU(self.embedding_size, self.hidden_size, self.num_layers, dropout=dp)\n        elif self.cell_type == \"LSTM\":\n            self.cell = nn.LSTM(self.embedding_size, self.hidden_size, self.num_layers, dropout=dp)\n        self.fc = nn.Linear(self.hidden_size, self.output_size)\n\n    def forward(self, x, hidden, cell):\n        \n        x = x.unsqueeze(0)\n\n        embedding = self.dropout(self.embedding(x))\n        \n\n        if self.cell_type == \"LSTM\":\n            outputs, (hidden, cell) = self.cell(embedding, (hidden, cell))\n        else:\n            outputs, hidden = self.cell(embedding, hidden)\n        \n\n        predictions = self.fc(outputs)\n\n        \n        predictions = predictions.squeeze(0)\n\n        return predictions, hidden, cell","metadata":{"execution":{"iopub.status.busy":"2023-05-23T11:45:41.927654Z","iopub.execute_input":"2023-05-23T11:45:41.928313Z","iopub.status.idle":"2023-05-23T11:45:41.940171Z","shell.execute_reply.started":"2023-05-23T11:45:41.928273Z","shell.execute_reply":"2023-05-23T11:45:41.939165Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, source, target, teacher_force_ratio=0.5):\n        batch_sz = source.shape[1]\n        target_len = target.shape[0]\n        target_vocab_size = self.decoder.output_size\n\n        outputs = torch.zeros(target_len, batch_sz, target_vocab_size).to(device)\n\n        hidden, cell = self.encoder(source)\n        hidden = hidden.repeat(self.decoder.num_layers,1,1)\n        if self.decoder.cell_type == \"LSTM\":\n            cell = cell.repeat(self.decoder.num_layers,1,1)\n\n        \n        x = target[0]\n\n        for t in range(1, target_len):\n            \n            output, hidden, cell = self.decoder(x, hidden, cell)\n\n            \n            outputs[t] = output\n\n            \n            best_guess = output.argmax(dim=1)\n\n            \n            x = target[t] if random.random() < teacher_force_ratio else best_guess\n\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2023-05-23T11:45:42.480832Z","iopub.execute_input":"2023-05-23T11:45:42.481171Z","iopub.status.idle":"2023-05-23T11:45:42.491113Z","shell.execute_reply.started":"2023-05-23T11:45:42.481142Z","shell.execute_reply":"2023-05-23T11:45:42.490074Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"def sum_accuracy(preds, target):\n    num_equal_columns = torch.logical_or(preds == target, target == PAD_idx).all(dim=0).sum().item()\n    return num_equal_columns","metadata":{"execution":{"iopub.status.busy":"2023-05-23T11:45:43.702927Z","iopub.execute_input":"2023-05-23T11:45:43.703300Z","iopub.status.idle":"2023-05-23T11:45:43.708237Z","shell.execute_reply.started":"2023-05-23T11:45:43.703269Z","shell.execute_reply":"2023-05-23T11:45:43.707271Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"def evaluateModel(model, dataloader, criterion, b_sz=32):\n    model.eval()\n    \n    n_data = len(dataloader) * b_sz\n    loss_epoch = 0\n    n_correct = 0\n    \n    with torch.no_grad():\n        for (input_seq, target_seq) in dataloader:\n            \n            input_seq = input_seq.T.to(device)\n            target_seq = target_seq.T.to(device)\n\n            \n            output = model(input_seq, target_seq, teacher_force_ratio=0.0)\n            \n            pred_seq = output.argmax(dim=2)\n            n_correct += sum_accuracy(pred_seq, target_seq)\n\n            \n            output = output[1:].reshape(-1, output.shape[2])\n            target = target_seq[1:].reshape(-1)\n            \n            loss = criterion(output, target)\n\n            loss_epoch += loss.item()\n        \n        acc = n_correct / n_data\n        acc = acc * 100.0\n        loss_epoch /= len(dataloader)\n        return loss_epoch, acc","metadata":{"execution":{"iopub.status.busy":"2023-05-23T11:45:46.427698Z","iopub.execute_input":"2023-05-23T11:45:46.428056Z","iopub.status.idle":"2023-05-23T11:45:46.436176Z","shell.execute_reply.started":"2023-05-23T11:45:46.428026Z","shell.execute_reply":"2023-05-23T11:45:46.435259Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"def saveAndEvaluate(model, dataloader, criterion, df, vocab, b_sz=32):\n    results = []\n    model.eval()\n    \n    n_data = len(dataloader) * b_sz\n    loss_epoch = 0\n    n_correct = 0\n    \n    with torch.no_grad():\n        for (input_seq, target_seq) in dataloader:\n            \n            input_seq = input_seq.T.to(device)\n            target_seq = target_seq.T.to(device)\n\n            \n            output = model(input_seq, target_seq, teacher_force_ratio=0.0)\n            \n            pred_seq = output.argmax(dim=2)\n            n_correct += sum_accuracy(pred_seq, target_seq)\n\n            \n            output = output[1:].reshape(-1, output.shape[2])\n            target = target_seq[1:].reshape(-1)\n            \n            loss = criterion(output, target)\n\n            loss_epoch += loss.item()\n            \n            pred_seq = pred_seq.T\n            for idx in range(b_sz):\n                word = wordFromTensor(pred_seq[idx], vocab)\n                results.append(word)\n                \n        acc = n_correct / n_data\n        acc = acc * 100.0\n        loss_epoch /= len(dataloader)\n        \n        df[2] = results\n        new_column_names = {0: 'Source', 1: 'Target', 2: 'Predicted'}\n        df = df.rename(columns=new_column_names)\n        df.to_csv(test_pred_path, index=False)\n        \n        return loss_epoch, acc, df","metadata":{"execution":{"iopub.status.busy":"2023-05-23T11:45:46.950765Z","iopub.execute_input":"2023-05-23T11:45:46.951113Z","iopub.status.idle":"2023-05-23T11:45:46.962603Z","shell.execute_reply.started":"2023-05-23T11:45:46.951086Z","shell.execute_reply":"2023-05-23T11:45:46.961268Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"def trainModel(model, criterion, optimizer, train_dataloader, valid_dataloader, num_epochs, batch_size=32):\n    start = time.time()\n    min_val_loss = 10000.0\n    min_val_epoch = 0\n    trigger = 0\n    \n    best_model_state = deepcopy(model.state_dict())\n    \n    tr_loss_list = []\n    tr_acc_list = []\n    val_loss_list = []\n    val_acc_list = []\n    for epoch in range(num_epochs):\n        print(f\"[Epoch {epoch+1} / {num_epochs}]\")\n        model.train()\n\n        for (input_seq, target_seq) in train_dataloader:\n            \n            input_seq = input_seq.T.to(device)\n            target_seq = target_seq.T.to(device)\n\n            \n            output = model(input_seq, target_seq)\n            \n            output = output[1:].reshape(-1, output.shape[2])\n            target = target_seq[1:].reshape(-1)\n\n            optimizer.zero_grad()\n            loss = criterion(output, target)\n\n            \n            loss.backward()\n\n            \n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n\n            \n            optimizer.step()\n\n        #-----------------------------------------------\n        # Train loss and accuracy\n        tr_loss, tr_acc = evaluateModel(model, train_dataloader, criterion, batch_size)\n        tr_loss_list.append(tr_loss)\n        tr_acc_list.append(tr_acc)\n        \n        print(f\"Training Loss: {tr_loss:.2f}\")\n        print(f\"Training Accuracy: {tr_acc:.2f}\")\n\n        #-----------------------------------------------\n        # Valid loss and accuracy\n        val_loss, val_acc = evaluateModel(model, valid_dataloader, criterion, batch_size)\n        val_loss_list.append(val_loss)\n        val_acc_list.append(val_acc)\n        \n        print(f\"Validation Loss: {val_loss:.2f}\")\n        print(f\"Validation Accuracy: {val_acc:.2f}\")\n\n        if val_loss <= min_val_loss:\n            best_model_state = deepcopy(model.state_dict())\n            trigger = 0\n            min_val_loss = val_loss\n            min_val_epoch = epoch\n        else:\n            trigger += 1\n        \n        end = time.time()\n        print(\"Time: \", timeInMinutes(end-start))\n        print(\"----------------------------------\")\n        \n        if trigger == 5:\n            print('Early stopping!')\n            break\n    \n    print('Saving the best model...')\n    torch.save(best_model_state, best_model_path)\n    print('Best model saved.')\n    return","metadata":{"execution":{"iopub.status.busy":"2023-05-23T11:46:03.386752Z","iopub.execute_input":"2023-05-23T11:46:03.387097Z","iopub.status.idle":"2023-05-23T11:46:03.400106Z","shell.execute_reply.started":"2023-05-23T11:46:03.387069Z","shell.execute_reply":"2023-05-23T11:46:03.399185Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"train_data_path = '/kaggle/input/eng-hin/hin_train.csv'\nvalid_data_path = '/kaggle/input/eng-hin/hin_valid.csv'\ntest_data_path = '/kaggle/input/eng-hin/hin_test.csv'\n\ntrain_data = pd.read_csv(train_data_path, sep=',', header=None).values\ntest_data = pd.read_csv(test_data_path, sep=',', header=None).values\nvalid_data = pd.read_csv(valid_data_path, sep=',', header=None).values","metadata":{"execution":{"iopub.status.busy":"2023-05-23T11:46:05.917489Z","iopub.execute_input":"2023-05-23T11:46:05.917930Z","iopub.status.idle":"2023-05-23T11:46:06.050585Z","shell.execute_reply.started":"2023-05-23T11:46:05.917894Z","shell.execute_reply":"2023-05-23T11:46:06.049631Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# build vocabulary\nx_vocab, y_vocab = prepareVocab(train_data)\n\nprint('Number of characters in Source Vocab :', x_vocab.n_chars-4)\nprint('Number of characters in Target Vocab :', y_vocab.n_chars-4)","metadata":{"execution":{"iopub.status.busy":"2023-05-23T11:46:06.512502Z","iopub.execute_input":"2023-05-23T11:46:06.513023Z","iopub.status.idle":"2023-05-23T11:46:07.041379Z","shell.execute_reply.started":"2023-05-23T11:46:06.512982Z","shell.execute_reply":"2023-05-23T11:46:07.040379Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Number of characters in Source Vocab : 26\nNumber of characters in Target Vocab : 64\n","output_type":"stream"}]},{"cell_type":"code","source":"x_train = processData(train_data[:,0], x_vocab, eos=True).to(device=device)\nx_test = processData(test_data[:,0], x_vocab, eos=True).to(device=device)\nx_valid = processData(valid_data[:,0], x_vocab, eos=True).to(device=device)\n\ny_train = processData(train_data[:,1], y_vocab, sos=True, eos=True).to(device=device)\ny_test = processData(test_data[:,1], y_vocab, sos=True, eos=True).to(device=device)\ny_valid = processData(valid_data[:,1], y_vocab, sos=True, eos=True).to(device=device)","metadata":{"execution":{"iopub.status.busy":"2023-05-23T11:46:09.946906Z","iopub.execute_input":"2023-05-23T11:46:09.947281Z","iopub.status.idle":"2023-05-23T11:46:11.813333Z","shell.execute_reply.started":"2023-05-23T11:46:09.947246Z","shell.execute_reply":"2023-05-23T11:46:11.812330Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"n_train = x_train.size(0)\nn_valid = x_valid.size(0)\nn_test = x_test.size(0)\nprint('Number of Training Sequences :', n_train)\nprint('Number of Validation Sequences :', n_valid)\nprint('Number of Test Sequences :', n_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-23T11:46:12.398690Z","iopub.execute_input":"2023-05-23T11:46:12.399047Z","iopub.status.idle":"2023-05-23T11:46:12.406580Z","shell.execute_reply.started":"2023-05-23T11:46:12.399019Z","shell.execute_reply":"2023-05-23T11:46:12.404720Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Number of Training Sequences : 51200\nNumber of Validation Sequences : 4096\nNumber of Test Sequences : 4096\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset = TensorDataset(x_train, y_train)\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\nvalid_dataset = TensorDataset(x_valid, y_valid)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=batch_size)\n\ntest_dataset = TensorDataset(x_test, y_test)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-05-23T11:46:15.167017Z","iopub.execute_input":"2023-05-23T11:46:15.167385Z","iopub.status.idle":"2023-05-23T11:46:15.174102Z","shell.execute_reply.started":"2023-05-23T11:46:15.167356Z","shell.execute_reply":"2023-05-23T11:46:15.173049Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"num_epochs = 15\nlearning_rate = 0.001\n\n# Fixed parameters for encoder and decoder\ninput_size_encoder = x_vocab.n_chars\ninput_size_decoder = y_vocab.n_chars\noutput_size = input_size_decoder","metadata":{"execution":{"iopub.status.busy":"2023-05-23T11:46:18.928584Z","iopub.execute_input":"2023-05-23T11:46:18.928935Z","iopub.status.idle":"2023-05-23T11:46:18.933422Z","shell.execute_reply.started":"2023-05-23T11:46:18.928907Z","shell.execute_reply":"2023-05-23T11:46:18.932479Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"# best hyperparameter configuration\nparams = {\n    'wandb_project' : 'dl_ass_3_q_4',\n    'wandb_entity' : 'cs22m059',\n    'dataset' : 'hin',\n    'cell_type' : 'LSTM',\n    'embedding_size' : 128,\n    'hidden_size' : 256,\n    'enc_num_layers' : 3,\n    'dec_num_layers' : 3,\n    'dropout' : 0.2,\n    'bidirectional' : 'Yes'\n}\n#--------------------------------------------\n# initialize wandb with given params\nwandb.init(project = params['wandb_project'], config = params)\nprint(\"Provided hyperparameters = \", params)\nparams = SimpleNamespace(**params)","metadata":{"execution":{"iopub.status.busy":"2023-05-23T11:46:22.523893Z","iopub.execute_input":"2023-05-23T11:46:22.524276Z","iopub.status.idle":"2023-05-23T11:46:54.908667Z","shell.execute_reply.started":"2023-05-23T11:46:22.524234Z","shell.execute_reply":"2023-05-23T11:46:54.907836Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs22m059\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230523_114622-h3j8gi1g</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m059/dl_ass_3_q_4/runs/h3j8gi1g' target=\"_blank\">pleasant-field-1</a></strong> to <a href='https://wandb.ai/cs22m059/dl_ass_3_q_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m059/dl_ass_3_q_4' target=\"_blank\">https://wandb.ai/cs22m059/dl_ass_3_q_4</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m059/dl_ass_3_q_4/runs/h3j8gi1g' target=\"_blank\">https://wandb.ai/cs22m059/dl_ass_3_q_4/runs/h3j8gi1g</a>"},"metadata":{}},{"name":"stdout","text":"Provided hyperparameters =  {'wandb_project': 'dl_ass_3_q_4', 'wandb_entity': 'cs22m059', 'dataset': 'hin', 'cell_type': 'LSTM', 'embedding_size': 128, 'hidden_size': 256, 'enc_num_layers': 3, 'dec_num_layers': 3, 'dropout': 0.2, 'bidirectional': 'Yes'}\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Building the model...\")\n# Model hyperparameters\ncell_type = params.cell_type\nembedding_size = params.embedding_size\nhidden_size = params.hidden_size  # Needs to be the same for both RNN's\nenc_num_layers = params.enc_num_layers\ndec_num_layers = params.dec_num_layers\ndropout = params.dropout\nbidirectional = True if params.bidirectional == \"Yes\" else False\n\nencoder_net = Encoder(\ncell_type, input_size_encoder, embedding_size, hidden_size, enc_num_layers, dropout, bidirectional).to(device)\n\ndecoder_net = Decoder(\n    cell_type,\n    input_size_decoder,\n    embedding_size,\n    hidden_size,\n    output_size,\n    dec_num_layers,\n    dropout,\n).to(device)\n\nmodel = Seq2Seq(encoder_net, decoder_net).to(device)\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\ncriterion = nn.CrossEntropyLoss()\n\ntrainModel(model, criterion, optimizer, train_dataloader, valid_dataloader, num_epochs, batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-05-23T11:47:14.263240Z","iopub.execute_input":"2023-05-23T11:47:14.263666Z","iopub.status.idle":"2023-05-23T12:02:29.606255Z","shell.execute_reply.started":"2023-05-23T11:47:14.263632Z","shell.execute_reply":"2023-05-23T12:02:29.605179Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"Building the model...\n[Epoch 1 / 15]\nTraining Loss: 0.65\nTraining Accuracy: 13.49\nValidation Loss: 0.54\nValidation Accuracy: 17.48\nTime:  1m 25s\n----------------------------------\n[Epoch 2 / 15]\nTraining Loss: 0.55\nTraining Accuracy: 25.12\nValidation Loss: 0.48\nValidation Accuracy: 27.81\nTime:  2m 49s\n----------------------------------\n[Epoch 3 / 15]\nTraining Loss: 0.50\nTraining Accuracy: 32.27\nValidation Loss: 0.46\nValidation Accuracy: 31.98\nTime:  4m 12s\n----------------------------------\n[Epoch 4 / 15]\nTraining Loss: 0.46\nTraining Accuracy: 37.46\nValidation Loss: 0.45\nValidation Accuracy: 34.67\nTime:  5m 36s\n----------------------------------\n[Epoch 5 / 15]\nTraining Loss: 0.43\nTraining Accuracy: 40.89\nValidation Loss: 0.44\nValidation Accuracy: 35.33\nTime:  6m 59s\n----------------------------------\n[Epoch 6 / 15]\nTraining Loss: 0.39\nTraining Accuracy: 45.28\nValidation Loss: 0.43\nValidation Accuracy: 37.21\nTime:  8m 22s\n----------------------------------\n[Epoch 7 / 15]\nTraining Loss: 0.38\nTraining Accuracy: 48.28\nValidation Loss: 0.44\nValidation Accuracy: 38.35\nTime:  9m 45s\n----------------------------------\n[Epoch 8 / 15]\nTraining Loss: 0.34\nTraining Accuracy: 51.79\nValidation Loss: 0.44\nValidation Accuracy: 39.62\nTime:  11m 7s\n----------------------------------\n[Epoch 9 / 15]\nTraining Loss: 0.31\nTraining Accuracy: 54.20\nValidation Loss: 0.43\nValidation Accuracy: 38.96\nTime:  12m 30s\n----------------------------------\n[Epoch 10 / 15]\nTraining Loss: 0.30\nTraining Accuracy: 56.95\nValidation Loss: 0.45\nValidation Accuracy: 39.18\nTime:  13m 53s\n----------------------------------\n[Epoch 11 / 15]\nTraining Loss: 0.28\nTraining Accuracy: 60.02\nValidation Loss: 0.45\nValidation Accuracy: 39.94\nTime:  15m 15s\n----------------------------------\nEarly stopping!\nSaving the best model...\nBest model saved.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load(best_model_path))\n\ntest_data_df = pd.read_csv(test_data_path, sep=',', header=None)\ntest_loss, test_acc, pred_df = saveAndEvaluate(model, test_dataloader, criterion, test_data_df, y_vocab, batch_size)\nprint(f\"Test Loss: {test_loss:.2f}\")\nprint(f\"Test Accuracy: {test_acc:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-23T12:09:04.677388Z","iopub.execute_input":"2023-05-23T12:09:04.677749Z","iopub.status.idle":"2023-05-23T12:09:08.265734Z","shell.execute_reply.started":"2023-05-23T12:09:04.677722Z","shell.execute_reply":"2023-05-23T12:09:08.264654Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"Test Loss: 0.51\nTest Accuracy: 35.18\n","output_type":"stream"}]},{"cell_type":"code","source":"# find Levenshtein distance for sample inputs and predictions\ndf_sample = pred_df.sample(n=10)\nlev_list = []\nfor ind in df_sample.index:\n    lev_list.append(distance(df_sample['Target'][ind], df_sample['Predicted'][ind]))\ndf_sample['Levenshtein'] = lev_list","metadata":{"execution":{"iopub.status.busy":"2023-05-23T12:10:34.253212Z","iopub.execute_input":"2023-05-23T12:10:34.253579Z","iopub.status.idle":"2023-05-23T12:10:34.264078Z","shell.execute_reply.started":"2023-05-23T12:10:34.253551Z","shell.execute_reply":"2023-05-23T12:10:34.261780Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"# display sample inputs and predictions\nfig = go.Figure(data=[go.Table(\n    header=dict(values=list(df_sample.columns),\n                fill_color='paleturquoise',\n                align='center',\n                font_size=18,\n                height=30\n                ),\n    cells=dict(values=[df_sample.Source, df_sample.Target, df_sample.Predicted, df_sample.Levenshtein],\n               fill_color='lavender',\n               align='center',\n               font_size=16,\n               height=30))\n])\n\nfig.update_layout(autosize=False, width=700, height=330, margin=dict(l=0,r=0,b=0,t=0))\nfig.show()\n\nwandb.log({'Sample Predictions': fig})","metadata":{"execution":{"iopub.status.busy":"2023-05-23T12:10:52.794592Z","iopub.execute_input":"2023-05-23T12:10:52.795151Z","iopub.status.idle":"2023-05-23T12:10:52.831263Z","shell.execute_reply.started":"2023-05-23T12:10:52.795117Z","shell.execute_reply":"2023-05-23T12:10:52.828722Z"},"trusted":true},"execution_count":77,"outputs":[{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"e31e1d1b-541e-4f7b-8e41-3cc45607b7ef\" class=\"plotly-graph-div\" style=\"height:330px; width:700px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e31e1d1b-541e-4f7b-8e41-3cc45607b7ef\")) {                    Plotly.newPlot(                        \"e31e1d1b-541e-4f7b-8e41-3cc45607b7ef\",                        [{\"cells\":{\"align\":\"center\",\"fill\":{\"color\":\"lavender\"},\"font\":{\"size\":16},\"height\":30,\"values\":[[\"prashnottari\",\"kasera\",\"rp\",\"heblikar\",\"rollers\",\"shrirampur\",\"jose\",\"nagmandal\",\"kamottejna\",\"matthe\"],[\"प्रश्नोत्तरी\",\"कसेरा\",\"आरपी\",\"हेब्लिकर\",\"रोलर्स\",\"श्रीरामपुर\",\"जोस\",\"नागमण्डल\",\"कामोत्तेजना\",\"मत्थे\"],[\"प्रश्नोत्तरी\",\"कासेरा\",\"आरपीआई\",\"हेल्लीकर\",\"रॉलर्स\",\"श्रीरामपुर\",\"जोस\",\"नागमंडल\",\"कामोत्तेजना\",\"मत्ते\"],[0,1,2,2,1,0,0,2,0,1]]},\"header\":{\"align\":\"center\",\"fill\":{\"color\":\"paleturquoise\"},\"font\":{\"size\":18},\"height\":30,\"values\":[\"Source\",\"Target\",\"Predicted\",\"Levenshtein\"]},\"type\":\"table\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"margin\":{\"l\":0,\"r\":0,\"b\":0,\"t\":0},\"autosize\":false,\"width\":700,\"height\":330},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('e31e1d1b-541e-4f7b-8e41-3cc45607b7ef');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"code","source":"# list of some wrongly predicted words\nsource_list = [\n    'foohadta',\n    'ukhrul',\n    'nabz',\n    'tarkvaad',\n    'phabti',\n    'barker',\n    'sanyukt',\n    'ikattha',\n    'achchi',\n    'vipannata',\n    'mckenzie',\n    'samruddhiyon',\n    'abdunnaasir',\n    'dayaalapuraa',\n    'karneshvardhaam',\n    'swaadpremiyon',\n    'naameegiraamee',\n    'manokaamnaaon',\n    'pratirodhaatmak',\n    'hastaantaraneey',\n    'utsaahawarddhan',\n    'shaasanadhikariyon',\n    'properfacebuk',\n    'varnavyavasthaavaadiyon'\n]","metadata":{"execution":{"iopub.status.busy":"2023-05-23T12:11:00.564065Z","iopub.execute_input":"2023-05-23T12:11:00.564439Z","iopub.status.idle":"2023-05-23T12:11:00.574779Z","shell.execute_reply.started":"2023-05-23T12:11:00.564408Z","shell.execute_reply":"2023-05-23T12:11:00.572693Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"# find the source, target and predicted from the pred_vanilla.csv \n# where source is in the source list\nsrc = []\ntgt = []\nprd = []\ndf_sample = pd.DataFrame()\n\nfor i in range(4096) :\n    if source_list.count(pred_df['Source'][i]) > 0:\n        src.append(pred_df['Source'][i])\n        tgt.append(pred_df['Target'][i])\n        prd.append(pred_df['Predicted'][i])","metadata":{"execution":{"iopub.status.busy":"2023-05-23T12:11:05.126174Z","iopub.execute_input":"2023-05-23T12:11:05.126549Z","iopub.status.idle":"2023-05-23T12:11:05.180308Z","shell.execute_reply.started":"2023-05-23T12:11:05.126521Z","shell.execute_reply":"2023-05-23T12:11:05.179229Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"df_sample['Source'] = src\ndf_sample['Target'] = tgt\ndf_sample['Predicted'] = prd","metadata":{"execution":{"iopub.status.busy":"2023-05-23T12:11:07.690622Z","iopub.execute_input":"2023-05-23T12:11:07.690973Z","iopub.status.idle":"2023-05-23T12:11:07.701941Z","shell.execute_reply.started":"2023-05-23T12:11:07.690945Z","shell.execute_reply":"2023-05-23T12:11:07.700838Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"# display inputs and predictions for the words in source list\nfig = go.Figure(data=[go.Table(\n    header=dict(values=list(df_sample.columns),\n                fill_color='paleturquoise',\n                align='center',\n                font_size=18,\n                height=30\n                ),\n    cells=dict(values=[df_sample.Source, df_sample.Target, df_sample.Predicted],\n               fill_color='lavender',\n               align='center',\n               font_size=16,\n               height=30))\n])\n\nfig.update_layout(autosize=False, width=700, height=750, margin=dict(l=0,r=0,b=0,t=0))\nfig.show()\n\nwandb.log({'Wrong Predictions': fig})\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2023-05-23T12:11:17.952962Z","iopub.execute_input":"2023-05-23T12:11:17.953362Z","iopub.status.idle":"2023-05-23T12:11:23.666060Z","shell.execute_reply.started":"2023-05-23T12:11:17.953329Z","shell.execute_reply":"2023-05-23T12:11:23.665228Z"},"trusted":true},"execution_count":81,"outputs":[{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"84258f15-6536-42a3-ad82-b6ac5aa1825a\" class=\"plotly-graph-div\" style=\"height:750px; width:700px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"84258f15-6536-42a3-ad82-b6ac5aa1825a\")) {                    Plotly.newPlot(                        \"84258f15-6536-42a3-ad82-b6ac5aa1825a\",                        [{\"cells\":{\"align\":\"center\",\"fill\":{\"color\":\"lavender\"},\"font\":{\"size\":16},\"height\":30,\"values\":[[\"foohadta\",\"ukhrul\",\"dayaalapuraa\",\"karneshvardhaam\",\"swaadpremiyon\",\"nabz\",\"tarkvaad\",\"phabti\",\"barker\",\"sanyukt\",\"ikattha\",\"naameegiraamee\",\"manokaamnaaon\",\"pratirodhaatmak\",\"hastaantaraneey\",\"utsaahawarddhan\",\"shaasanadhikariyon\",\"properfacebuk\",\"varnavyavasthaavaadiyon\",\"achchi\",\"vipannata\",\"mckenzie\",\"samruddhiyon\",\"abdunnaasir\"],[\"फूहड़ता\",\"उखरुल\",\"दयालपुरा\",\"कर्णेश्वरधाम\",\"स्वादप्रेमियों\",\"नब्ज़\",\"तर्कवाद\",\"फब्ती\",\"बार्कर\",\"संयुक्त\",\"इकट्ठा\",\"नामीगिरामी\",\"मनोकामनाओं\",\"प्रतिरोधात्मक\",\"हस्तांतरणीय\",\"उत्साहवर्द्धन\",\"शासनाधिकारियों\",\"प्रॉपरफेसबुक\",\"वर्णव्यवस्थावादियों\",\"अच्छी\",\"विपन्नता\",\"मैकेंज़ी\",\"समृद्धियों\",\"अब्दुन्नासिर\"],[\"फूहद़ता\",\"उखरूल\",\"दयालापुरा\",\"कर्नश्वरधाम\",\"स्वाद्रेमियों\",\"नब्ज\",\"तरक्वाद\",\"फबती\",\"बारकर\",\"सनयुक्त\",\"इकत्था\",\"नामीगरीमी\",\"मनोकामााओं\",\"प्रतिधोरत्मक\",\"हस्तांतररीय\",\"उत्सहार्द्रध्धन\",\"शासानाधिकारियों\",\"प्रोपफफेेसबब\",\"वर्वव्यववत्वादादियों\",\"अच्ची\",\"विपनननता\",\"मैकेेंजी\",\"समुद्ध्धियों\",\"अब्दुनननसीर\"]]},\"header\":{\"align\":\"center\",\"fill\":{\"color\":\"paleturquoise\"},\"font\":{\"size\":18},\"height\":30,\"values\":[\"Source\",\"Target\",\"Predicted\"]},\"type\":\"table\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"margin\":{\"l\":0,\"r\":0,\"b\":0,\"t\":0},\"autosize\":false,\"width\":700,\"height\":750},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('84258f15-6536-42a3-ad82-b6ac5aa1825a');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.020 MB of 0.020 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1c8f9fedbd24519905dfb401894c8cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">pleasant-field-1</strong> at: <a href='https://wandb.ai/cs22m059/dl_ass_3_q_4/runs/h3j8gi1g' target=\"_blank\">https://wandb.ai/cs22m059/dl_ass_3_q_4/runs/h3j8gi1g</a><br/>Synced 6 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230523_114622-h3j8gi1g/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}