{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-05-19T18:37:17.359997Z","iopub.execute_input":"2023-05-19T18:37:17.360479Z","iopub.status.idle":"2023-05-19T18:37:17.380027Z","shell.execute_reply.started":"2023-05-19T18:37:17.360439Z","shell.execute_reply":"2023-05-19T18:37:17.378494Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/eng-san/san_train.csv\n/kaggle/input/eng-san/san_valid.csv\n/kaggle/input/eng-san/san_test.csv\n/kaggle/input/eng-hin/hin_valid.csv\n/kaggle/input/eng-hin/hin_test.csv\n/kaggle/input/eng-hin/hin_train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# import cell\n%matplotlib inline\nimport random\nimport wandb\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import TensorDataset\n\nimport time\nimport math\n\nwandb.login(key='5341282441ecc95a5e6aefa6dbf5bd13600c5852')","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:17.381455Z","iopub.execute_input":"2023-05-19T18:37:17.381756Z","iopub.status.idle":"2023-05-19T18:37:22.047278Z","shell.execute_reply.started":"2023-05-19T18:37:17.381730Z","shell.execute_reply":"2023-05-19T18:37:22.046314Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs22m059\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nSOS_token = \"@\"\nEOS_token = \"#\"\nPAD_token = \"^\"\nUNK_token = \"$\"\n\nSOS_idx = 0\nEOS_idx = 1\nPAD_idx = 2\nUNK_idx = 3\n\nbatch_size = 32","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:22.048613Z","iopub.execute_input":"2023-05-19T18:37:22.049245Z","iopub.status.idle":"2023-05-19T18:37:22.123938Z","shell.execute_reply.started":"2023-05-19T18:37:22.049209Z","shell.execute_reply":"2023-05-19T18:37:22.122782Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"def timeInMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    s = format(s, \".0f\")\n    return str(m) + \"m \" + str(s) + \"s\"","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:22.129800Z","iopub.execute_input":"2023-05-19T18:37:22.130804Z","iopub.status.idle":"2023-05-19T18:37:22.136376Z","shell.execute_reply.started":"2023-05-19T18:37:22.130762Z","shell.execute_reply":"2023-05-19T18:37:22.135362Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class Script:\n    def __init__(self, name):\n        self.name = name\n        self.char2index = {SOS_token: SOS_idx, EOS_token: EOS_idx, PAD_token: PAD_idx, UNK_token: UNK_idx}\n        self.char2count = {}\n        self.index2char = {SOS_idx: SOS_token, EOS_idx: EOS_token, PAD_idx: PAD_token, UNK_idx: UNK_token}\n        self.n_chars = 4  # Count SOS, EOS, PAD and UNK\n\n    def addWord(self, word):\n        for char in word:\n            self.addChar(char)\n\n    def addChar(self, char):\n        if char not in self.char2index:\n            self.char2index[char] = self.n_chars\n            self.char2count[char] = 1\n            self.index2char[self.n_chars] = char\n            self.n_chars += 1\n        else:\n            self.char2count[char] += 1","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:22.137865Z","iopub.execute_input":"2023-05-19T18:37:22.138374Z","iopub.status.idle":"2023-05-19T18:37:22.149777Z","shell.execute_reply.started":"2023-05-19T18:37:22.138340Z","shell.execute_reply":"2023-05-19T18:37:22.148807Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def prepareVocab(data, in_scr=\"lat\", out_scr=\"dev\"):\n    input_vocab = Script(in_scr)\n    output_vocab = Script(out_scr)\n    \n    for pair in data:\n        input_vocab.addWord(pair[0])\n        output_vocab.addWord(pair[1])\n    \n    return input_vocab, output_vocab","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:22.152405Z","iopub.execute_input":"2023-05-19T18:37:22.153051Z","iopub.status.idle":"2023-05-19T18:37:22.164810Z","shell.execute_reply.started":"2023-05-19T18:37:22.153026Z","shell.execute_reply":"2023-05-19T18:37:22.163825Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def tensorFromWord(word, vocab, sos=False, eos=False):\n    char_list = []\n    if sos:\n        char_list.append(vocab.char2index[SOS_token])\n    for char in word:\n        if char in vocab.char2index:\n            char_list.append(vocab.char2index[char])\n        else:\n            char_list.append(vocab.char2index[UNK_token])\n    if eos:\n        char_list.append(vocab.char2index[EOS_token])\n    char_tensor = torch.tensor(char_list, dtype=torch.long)\n    return char_tensor","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:22.167281Z","iopub.execute_input":"2023-05-19T18:37:22.169378Z","iopub.status.idle":"2023-05-19T18:37:22.176942Z","shell.execute_reply.started":"2023-05-19T18:37:22.169349Z","shell.execute_reply":"2023-05-19T18:37:22.175928Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def processData(data, vocab, sos=False, eos=False):\n    tensor_list = []\n    for word in data:\n        word_tensor = tensorFromWord(word, vocab, sos, eos)\n        tensor_list.append(word_tensor)\n    word_tensor_pad = pad_sequence(tensor_list, padding_value=PAD_idx, batch_first=True)\n    return word_tensor_pad","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:22.180150Z","iopub.execute_input":"2023-05-19T18:37:22.180467Z","iopub.status.idle":"2023-05-19T18:37:22.188586Z","shell.execute_reply.started":"2023-05-19T18:37:22.180433Z","shell.execute_reply":"2023-05-19T18:37:22.187677Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def wordFromTensor(word_tensor, vocab):\n    word = \"\"\n    for idx in word_tensor:\n        if idx == EOS_idx:\n            break\n        if idx >= UNK_idx:\n            word += vocab.index2char[idx.item()]\n    return word","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:22.191101Z","iopub.execute_input":"2023-05-19T18:37:22.191997Z","iopub.status.idle":"2023-05-19T18:37:22.199336Z","shell.execute_reply.started":"2023-05-19T18:37:22.191963Z","shell.execute_reply":"2023-05-19T18:37:22.198581Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, cell_type, input_size, embedding_size, hidden_size, num_layers, dp, bidir=False):\n        super(Encoder, self).__init__()\n        self.cell_type = cell_type\n        self.input_size = input_size\n        self.embedding_size = embedding_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.dropout = nn.Dropout(dp)\n        self.bidir = bidir\n        \n        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n        if self.num_layers == 1:\n            dp = 0.0\n        if self.cell_type == \"RNN\":\n            self.cell = nn.RNN(self.embedding_size, self.hidden_size, self.num_layers, dropout=dp, bidirectional=self.bidir)\n        elif self.cell_type == \"GRU\":\n            self.cell = nn.GRU(self.embedding_size, self.hidden_size, self.num_layers, dropout=dp, bidirectional=self.bidir)\n        elif self.cell_type == \"LSTM\":\n            self.cell = nn.LSTM(self.embedding_size, self.hidden_size, self.num_layers, dropout=dp, bidirectional=self.bidir)\n\n    def forward(self, x):\n        # x shape: (seq_length, N) where N is batch size\n\n        embedding = self.dropout(self.embedding(x))\n        # embedding shape: (seq_length, N, embedding_size)\n        \n        cell = None\n        if self.cell_type == \"LSTM\":\n            outputs, (hidden, cell) = self.cell(embedding)\n            if self.bidir:\n                b_sz = cell.size(1)\n                cell = cell.view(self.num_layers, 2, b_sz, -1)\n                cell = cell[-1]\n                cell = cell.mean(axis=0)\n            else:\n                cell = cell[-1,:,:]\n            cell = cell.unsqueeze(0)\n        else:\n            outputs, hidden = self.cell(embedding)\n        \n        if self.bidir:\n            b_sz = hidden.size(1)\n            hidden = hidden.view(self.num_layers, 2, b_sz, -1)\n            hidden = hidden[-1]\n            hidden = hidden.mean(axis=0)\n        else:\n            hidden = hidden[-1,:,:]\n        hidden = hidden.unsqueeze(0)\n        # outputs shape: (seq_length, N, hidden_size)\n\n        return hidden, cell","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:22.201016Z","iopub.execute_input":"2023-05-19T18:37:22.201458Z","iopub.status.idle":"2023-05-19T18:37:22.216175Z","shell.execute_reply.started":"2023-05-19T18:37:22.201411Z","shell.execute_reply":"2023-05-19T18:37:22.215353Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(\n        self, cell_type, input_size, embedding_size, hidden_size, output_size, num_layers, dp\n    ):\n        super(Decoder, self).__init__()\n        self.cell_type = cell_type\n        self.input_size = input_size\n        self.embedding_size = embedding_size\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.num_layers = num_layers\n        self.dropout = nn.Dropout(dp)\n\n        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n        if self.num_layers == 1:\n            dp = 0.0\n        if self.cell_type == \"RNN\":\n            self.cell = nn.RNN(self.embedding_size, self.hidden_size, self.num_layers, dropout=dp)\n        elif self.cell_type == \"GRU\":\n            self.cell = nn.GRU(self.embedding_size, self.hidden_size, self.num_layers, dropout=dp)\n        elif self.cell_type == \"LSTM\":\n            self.cell = nn.LSTM(self.embedding_size, self.hidden_size, self.num_layers, dropout=dp)\n        self.fc = nn.Linear(self.hidden_size, self.output_size)\n\n    def forward(self, x, hidden, cell):\n        # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n        # is 1 here because we are sending in a single word and not a sentence\n        x = x.unsqueeze(0)\n\n        embedding = self.dropout(self.embedding(x))\n        # embedding shape: (1, N, embedding_size)\n\n        if self.cell_type == \"LSTM\":\n            outputs, (hidden, cell) = self.cell(embedding, (hidden, cell))\n        else:\n            outputs, hidden = self.cell(embedding, hidden)\n        # outputs shape: (1, N, hidden_size)\n\n        predictions = self.fc(outputs)\n\n        # predictions shape: (1, N, length_target_vocabulary) to send it to\n        # loss function we want it to be (N, length_target_vocabulary) so we're\n        # just gonna remove the first dim\n        predictions = predictions.squeeze(0)\n\n        return predictions, hidden, cell","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:22.217786Z","iopub.execute_input":"2023-05-19T18:37:22.218439Z","iopub.status.idle":"2023-05-19T18:37:22.234442Z","shell.execute_reply.started":"2023-05-19T18:37:22.218407Z","shell.execute_reply":"2023-05-19T18:37:22.233357Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, source, target, teacher_force_ratio=0.5):\n        batch_sz = source.shape[1]\n        target_len = target.shape[0]\n        target_vocab_size = self.decoder.output_size\n\n        outputs = torch.zeros(target_len, batch_sz, target_vocab_size).to(device)\n\n        hidden, cell = self.encoder(source)\n        hidden = hidden.repeat(self.decoder.num_layers,1,1)\n        if self.decoder.cell_type == \"LSTM\":\n            cell = cell.repeat(self.decoder.num_layers,1,1)\n\n        # Grab the first input to the Decoder which will be <SOS> token\n        x = target[0]\n\n        for t in range(1, target_len):\n            # Use previous hidden, cell as context from encoder at start\n            output, hidden, cell = self.decoder(x, hidden, cell)\n\n            # Store next output prediction\n            outputs[t] = output\n\n            # Get the best word the Decoder predicted (index in the vocabulary)\n            best_guess = output.argmax(dim=1)\n\n            # With probability of teacher_force_ratio we take the actual next word\n            # otherwise we take the word that the Decoder predicted it to be.\n            # Teacher Forcing is used so that the model gets used to seeing\n            # similar inputs at training and testing time, if teacher forcing is 1\n            # then inputs at test time might be completely different than what the\n            # network is used to. This was a long comment.\n            x = target[t] if random.random() < teacher_force_ratio else best_guess\n\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:22.236012Z","iopub.execute_input":"2023-05-19T18:37:22.237181Z","iopub.status.idle":"2023-05-19T18:37:22.252982Z","shell.execute_reply.started":"2023-05-19T18:37:22.237096Z","shell.execute_reply":"2023-05-19T18:37:22.251924Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def sum_accuracy(preds, target):\n    num_equal_columns = torch.logical_or(preds == target, target == PAD_idx).all(dim=0).sum().item()\n    return num_equal_columns","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:22.259016Z","iopub.execute_input":"2023-05-19T18:37:22.259311Z","iopub.status.idle":"2023-05-19T18:37:22.267943Z","shell.execute_reply.started":"2023-05-19T18:37:22.259269Z","shell.execute_reply":"2023-05-19T18:37:22.266930Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def evaluateModel(model, dataloader, criterion, b_sz=32):\n    model.eval()\n    \n    n_data = len(dataloader) * b_sz\n    loss_epoch = 0\n    n_correct = 0\n    \n    with torch.no_grad():\n        for batch_idx, (input_seq, target_seq) in enumerate(dataloader):\n            # Get input and targets and get to cuda\n            input_seq = input_seq.T.to(device)\n            target_seq = target_seq.T.to(device)\n\n            # Forward prop\n            output = model(input_seq, target_seq, teacher_force_ratio=0.0)\n            \n            pred_seq = output.argmax(dim=2)\n            n_correct += sum_accuracy(pred_seq, target_seq)\n\n            # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n            # doesn't take input in that form. For example if we have MNIST we want to have\n            # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n            # way that we have output_words * batch_size that we want to send in into\n            # our cost function, so we need to do some reshapin. While we're at it\n            # Let's also remove the start token while we're at it\n            output = output[1:].reshape(-1, output.shape[2])\n            target = target_seq[1:].reshape(-1)\n            \n            loss = criterion(output, target)\n\n            loss_epoch += loss.item()\n        \n        acc = n_correct / n_data\n        acc = acc * 100.0\n        loss_epoch /= len(dataloader)\n        return loss_epoch, acc","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:22.269424Z","iopub.execute_input":"2023-05-19T18:37:22.269982Z","iopub.status.idle":"2023-05-19T18:37:22.280988Z","shell.execute_reply.started":"2023-05-19T18:37:22.269948Z","shell.execute_reply":"2023-05-19T18:37:22.279685Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def trainModel(model, criterion, optimizer, train_dataloader, valid_dataloader, num_epochs, batch_size=32):\n#     start = time.time()\n    max_val_acc = -1.0\n    max_val_epoch = 0\n    trigger = 0\n    \n    tr_loss_list = []\n    tr_acc_list = []\n    val_loss_list = []\n    val_acc_list = []\n    for epoch in range(num_epochs):\n#         print(f\"[Epoch {epoch+1} / {num_epochs}]\")\n        \n        model.train()\n\n        for batch_idx, (input_seq, target_seq) in enumerate(train_dataloader):\n            # Get input and targets and get to cuda\n            input_seq = input_seq.T.to(device)\n            target_seq = target_seq.T.to(device)\n\n            # Forward prop\n            output = model(input_seq, target_seq)\n            # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n            # doesn't take input in that form. For example if we have MNIST we want to have\n            # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n            # way that we have output_words * batch_size that we want to send in into\n            # our cost function, so we need to do some reshapin. While we're at it\n            # Let's also remove the start token while we're at it\n            output = output[1:].reshape(-1, output.shape[2])\n            target = target_seq[1:].reshape(-1)\n\n            optimizer.zero_grad()\n            loss = criterion(output, target)\n\n            # Back prop\n            loss.backward()\n\n            # Clip to avoid exploding gradient issues, makes sure grads are\n            # within a healthy range\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n\n            # Gradient descent step\n            optimizer.step()\n\n        #-----------------------------------------------\n        # Train loss and accuracy\n        tr_loss, tr_acc = evaluateModel(model, train_dataloader, criterion, batch_size)\n        tr_loss_list.append(tr_loss)\n        tr_acc_list.append(tr_acc)\n#         print(f\"Training Loss: {tr_loss:.2f}\")\n#         print(f\"Training Accuracy: {tr_acc:.2f}\")\n        \n\n        #-----------------------------------------------\n        # Valid loss and accuracy\n        val_loss, val_acc = evaluateModel(model, valid_dataloader, criterion, batch_size)\n        val_loss_list.append(val_loss)\n        val_acc_list.append(val_acc)\n#         print(f\"Validation Loss: {val_loss:.2f}\")\n#         print(f\"Validation Accuracy: {val_acc:.2f}\")\n\n#         wandb.log({'tr_loss' : tr_loss, 'tr_acc' : tr_acc, 'val_loss' : val_loss, 'val_acc' : val_acc})\n\n        if val_acc >= max_val_acc:\n            trigger = 0\n            max_val_acc = val_acc\n            max_val_epoch = epoch\n        else:\n            trigger += 1\n        \n        if trigger == 5:\n            print('Early stopping!')\n            break\n\n#         end = time.time()\n#         print(\"Time: \", timeInMinutes(end-start))\n#         print(\"----------------------------------\")\n    for i in range(max_val_epoch+1):\n        wandb.log({'tr_loss' : tr_loss_list[i], 'tr_acc' : tr_acc_list[i], 'val_loss' : val_loss_list[i], 'val_acc' : val_acc_list[i]})","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:22.282590Z","iopub.execute_input":"2023-05-19T18:37:22.283088Z","iopub.status.idle":"2023-05-19T18:37:22.299246Z","shell.execute_reply.started":"2023-05-19T18:37:22.283055Z","shell.execute_reply":"2023-05-19T18:37:22.298455Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# load dataset\ntrain_data = pd.read_csv('/kaggle/input/eng-hin/hin_train.csv', sep=',', header=None).values\ntest_data = pd.read_csv('/kaggle/input/eng-hin/hin_test.csv', sep=',', header=None).values\nvalid_data = pd.read_csv('/kaggle/input/eng-hin/hin_valid.csv', sep=',', header=None).values","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:22.301301Z","iopub.execute_input":"2023-05-19T18:37:22.302182Z","iopub.status.idle":"2023-05-19T18:37:22.410209Z","shell.execute_reply.started":"2023-05-19T18:37:22.302147Z","shell.execute_reply":"2023-05-19T18:37:22.409279Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# build vocabulary\nx_vocab, y_vocab = prepareVocab(train_data)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:22.411838Z","iopub.execute_input":"2023-05-19T18:37:22.412265Z","iopub.status.idle":"2023-05-19T18:37:22.836434Z","shell.execute_reply.started":"2023-05-19T18:37:22.412231Z","shell.execute_reply":"2023-05-19T18:37:22.835364Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(x_vocab.n_chars)\nprint(y_vocab.n_chars)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:22.837661Z","iopub.execute_input":"2023-05-19T18:37:22.838036Z","iopub.status.idle":"2023-05-19T18:37:22.845664Z","shell.execute_reply.started":"2023-05-19T18:37:22.838002Z","shell.execute_reply":"2023-05-19T18:37:22.844556Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"30\n68\n","output_type":"stream"}]},{"cell_type":"code","source":"x_train = processData(train_data[:,0], x_vocab, eos=True).to(device=device)\nx_test = processData(test_data[:,0], x_vocab, eos=True).to(device=device)\nx_valid = processData(valid_data[:,0], x_vocab, eos=True).to(device=device)\n\ny_train = processData(train_data[:,1], y_vocab, sos=True, eos=True).to(device=device)\ny_test = processData(test_data[:,1], y_vocab, sos=True, eos=True).to(device=device)\ny_valid = processData(valid_data[:,1], y_vocab, sos=True, eos=True).to(device=device)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:22.847309Z","iopub.execute_input":"2023-05-19T18:37:22.848075Z","iopub.status.idle":"2023-05-19T18:37:26.760963Z","shell.execute_reply.started":"2023-05-19T18:37:22.847998Z","shell.execute_reply":"2023-05-19T18:37:26.759828Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"n_train = x_train.size(0)\nn_valid = x_valid.size(0)\nn_test = x_test.size(0)\n\nprint(n_train, n_valid, n_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:26.763406Z","iopub.execute_input":"2023-05-19T18:37:26.763741Z","iopub.status.idle":"2023-05-19T18:37:26.771823Z","shell.execute_reply.started":"2023-05-19T18:37:26.763712Z","shell.execute_reply":"2023-05-19T18:37:26.770605Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"51200 4096 4096\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset = TensorDataset(x_train, y_train)\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\nvalid_dataset = TensorDataset(x_valid, y_valid)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:26.773629Z","iopub.execute_input":"2023-05-19T18:37:26.774382Z","iopub.status.idle":"2023-05-19T18:37:26.784623Z","shell.execute_reply.started":"2023-05-19T18:37:26.774342Z","shell.execute_reply":"2023-05-19T18:37:26.783673Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"sweep_config = {\n    'method': 'bayes',\n    'name' : 'Bayesian_sweep',\n    'metric': {\n      'name': 'val_acc',\n      'goal': 'maximize'\n    },\n    'parameters': {\n        'cell_type' : {\n            'values' : ['LSTM', 'GRU', 'RNN']\n        },\n        'embedding_size': {\n            'values': [64, 128, 256]\n        },\n         'hidden_size': {\n            'values': [64, 128, 256]\n        },\n        'enc_num_layers': {\n            'values': [1, 2, 3]\n        },\n        'dec_num_layers': {\n            'values': [1, 2, 3]\n        },\n         'dropout': {\n            'values': [0.0, 0.2, 0.3]         \n        },\n        'bidirectional': {\n            'values': ['Yes', 'No']   \n        },\n    }\n}\n\nsweep_id = wandb.sweep(sweep = sweep_config, project = 'dl_assgn_3_q_2')","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:26.786379Z","iopub.execute_input":"2023-05-19T18:37:26.787270Z","iopub.status.idle":"2023-05-19T18:37:26.796661Z","shell.execute_reply.started":"2023-05-19T18:37:26.787231Z","shell.execute_reply":"2023-05-19T18:37:26.795616Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def main():\n    with wandb.init() as run:\n        run_name = 'cell_' + wandb.config.cell_type + '_enc-n-l_' + str(wandb.config.enc_num_layers) + '_dec-n-l_' + str(wandb.config.dec_num_layers) +\\\n                    '_emb-sz_' + str(wandb.config.embedding_size) + '_hid-sz_' + str(wandb.config.hidden_size) + \\\n                    '_dp_' + str(wandb.config.dropout) + '_bidir_' + wandb.config.bidirectional\n        wandb.run.name = run_name\n\n        num_epochs = 15\n        learning_rate = 0.001\n\n        # Fixed parameters for encoder and decoder\n        input_size_encoder = x_vocab.n_chars\n        input_size_decoder = y_vocab.n_chars\n        output_size = input_size_decoder\n\n        # Model hyperparameters\n        cell_type = wandb.config.cell_type\n        embedding_size = wandb.config.embedding_size\n        hidden_size = wandb.config.hidden_size  # Needs to be the same for both RNN's\n        enc_num_layers = wandb.config.enc_num_layers\n        dec_num_layers = wandb.config.dec_num_layers\n        dropout = wandb.config.dropout\n        bidirectional = True if wandb.config.bidirectional == \"Yes\" else False\n\n        encoder_net = Encoder(\n        cell_type, input_size_encoder, embedding_size, hidden_size, enc_num_layers, dropout, bidirectional).to(device)\n\n        decoder_net = Decoder(\n            cell_type,\n            input_size_decoder,\n            embedding_size,\n            hidden_size,\n            output_size,\n            dec_num_layers,\n            dropout,\n        ).to(device)\n\n        model = Seq2Seq(encoder_net, decoder_net).to(device)\n        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n        criterion = nn.CrossEntropyLoss()\n        \n        trainModel(model, criterion, optimizer, train_dataloader, valid_dataloader, num_epochs, batch_size)\n    \nwandb.agent(sweep_id, function = main, count = 100)\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:37:58.674063Z","iopub.execute_input":"2023-05-19T18:37:58.674456Z","iopub.status.idle":"2023-05-19T18:48:48.841427Z","shell.execute_reply.started":"2023-05-19T18:37:58.674425Z","shell.execute_reply":"2023-05-19T18:48:48.840217Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wl7dbvu0 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: Yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_num_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_num_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230519_183801-wl7dbvu0</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m059/test-dl/runs/wl7dbvu0' target=\"_blank\">lilac-sweep-1</a></strong> to <a href='https://wandb.ai/cs22m059/test-dl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m059/test-dl/sweeps/jajw7b5i' target=\"_blank\">https://wandb.ai/cs22m059/test-dl/sweeps/jajw7b5i</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m059/test-dl' target=\"_blank\">https://wandb.ai/cs22m059/test-dl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m059/test-dl/sweeps/jajw7b5i' target=\"_blank\">https://wandb.ai/cs22m059/test-dl/sweeps/jajw7b5i</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m059/test-dl/runs/wl7dbvu0' target=\"_blank\">https://wandb.ai/cs22m059/test-dl/runs/wl7dbvu0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>tr_acc</td><td>▁▅█</td></tr><tr><td>tr_loss</td><td>█▂▁</td></tr><tr><td>val_acc</td><td>▁▆█</td></tr><tr><td>val_loss</td><td>█▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>tr_acc</td><td>23.60352</td></tr><tr><td>tr_loss</td><td>0.59868</td></tr><tr><td>val_acc</td><td>27.53906</td></tr><tr><td>val_loss</td><td>0.50947</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lilac-sweep-1</strong> at: <a href='https://wandb.ai/cs22m059/test-dl/runs/wl7dbvu0' target=\"_blank\">https://wandb.ai/cs22m059/test-dl/runs/wl7dbvu0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230519_183801-wl7dbvu0/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t2mbzyzw with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: Yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_num_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_num_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230519_184329-t2mbzyzw</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m059/test-dl/runs/t2mbzyzw' target=\"_blank\">sunny-sweep-2</a></strong> to <a href='https://wandb.ai/cs22m059/test-dl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m059/test-dl/sweeps/jajw7b5i' target=\"_blank\">https://wandb.ai/cs22m059/test-dl/sweeps/jajw7b5i</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m059/test-dl' target=\"_blank\">https://wandb.ai/cs22m059/test-dl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m059/test-dl/sweeps/jajw7b5i' target=\"_blank\">https://wandb.ai/cs22m059/test-dl/sweeps/jajw7b5i</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m059/test-dl/runs/t2mbzyzw' target=\"_blank\">https://wandb.ai/cs22m059/test-dl/runs/t2mbzyzw</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>tr_acc</td><td>▁▆█</td></tr><tr><td>tr_loss</td><td>█▃▁</td></tr><tr><td>val_acc</td><td>▁▆█</td></tr><tr><td>val_loss</td><td>█▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>tr_acc</td><td>23.38867</td></tr><tr><td>tr_loss</td><td>0.5827</td></tr><tr><td>val_acc</td><td>26.53809</td></tr><tr><td>val_loss</td><td>0.49391</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">sunny-sweep-2</strong> at: <a href='https://wandb.ai/cs22m059/test-dl/runs/t2mbzyzw' target=\"_blank\">https://wandb.ai/cs22m059/test-dl/runs/t2mbzyzw</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230519_184329-t2mbzyzw/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}