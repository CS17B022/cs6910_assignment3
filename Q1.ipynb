{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-06T19:26:22.253597Z","iopub.execute_input":"2023-05-06T19:26:22.254025Z","iopub.status.idle":"2023-05-06T19:26:22.279596Z","shell.execute_reply.started":"2023-05-06T19:26:22.253987Z","shell.execute_reply":"2023-05-06T19:26:22.278785Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/eng-hin/hin_valid.csv\n/kaggle/input/eng-hin/hin_test.csv\n/kaggle/input/eng-hin/hin_train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# import cell\nimport torch\nfrom torch.nn.utils.rnn import pad_sequence","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:26:22.281557Z","iopub.execute_input":"2023-05-06T19:26:22.282344Z","iopub.status.idle":"2023-05-06T19:26:23.916305Z","shell.execute_reply.started":"2023-05-06T19:26:22.282300Z","shell.execute_reply":"2023-05-06T19:26:23.914957Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"SOS_token = \"SOS\"\nEOS_token = \"EOS\"\nPAD_token = \"PAD\"\nUNK_token = \"UNK\"\n\nSOS_idx = 0\nEOS_idx = 1\nPAD_idx = 2\nUNK_idx = 3\n\nclass Script:\n    def __init__(self, name):\n        self.name = name\n        self.char2index = {SOS_token: SOS_idx, EOS_token: EOS_idx, PAD_token: PAD_idx, UNK_token: UNK_idx}\n        self.char2count = {}\n        self.index2char = {SOS_idx: SOS_token, EOS_idx: EOS_token, PAD_idx: PAD_token, UNK_idx: UNK_token}\n        self.n_chars = 4  # Count SOS, EOS, PAD and UNK\n\n    def addWord(self, word):\n        for char in word:\n            self.addChar(char)\n\n    def addChar(self, char):\n        if char not in self.char2index:\n            self.char2index[char] = self.n_chars\n            self.char2count[char] = 1\n            self.index2char[self.n_chars] = char\n            self.n_chars += 1\n        else:\n            self.char2count[char] += 1","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:26:23.917773Z","iopub.execute_input":"2023-05-06T19:26:23.918382Z","iopub.status.idle":"2023-05-06T19:26:23.928142Z","shell.execute_reply.started":"2023-05-06T19:26:23.918346Z","shell.execute_reply":"2023-05-06T19:26:23.926827Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def prepareVocab(data, in_scr=\"lat\", out_scr=\"dev\"):\n    input_vocab = Script(in_scr)\n    output_vocab = Script(out_scr)\n    \n    for pair in data.values:\n        input_vocab.addWord(pair[0])\n        output_vocab.addWord(pair[1])\n    \n    return input_vocab, output_vocab","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:26:23.929828Z","iopub.execute_input":"2023-05-06T19:26:23.930280Z","iopub.status.idle":"2023-05-06T19:26:23.939467Z","shell.execute_reply.started":"2023-05-06T19:26:23.930245Z","shell.execute_reply":"2023-05-06T19:26:23.938381Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def tensorFromWord(vocab, word, sos=True, eos=True):\n    char_list = []\n    if sos:\n        char_list.append(vocab.char2index[SOS_token])\n    for char in word:\n        if char in vocab.char2index:\n            char_list.append(vocab.char2index[char])\n        else:\n            char_list.append(vocab.char2index[UNK_token])\n    if eos:\n        char_list.append(vocab.char2index[EOS_token])\n    char_tensor = torch.tensor(char_list, dtype=torch.int)\n    return char_tensor","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:26:23.944369Z","iopub.execute_input":"2023-05-06T19:26:23.944738Z","iopub.status.idle":"2023-05-06T19:26:23.958326Z","shell.execute_reply.started":"2023-05-06T19:26:23.944706Z","shell.execute_reply":"2023-05-06T19:26:23.957002Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def processData(data, in_vocab, out_vocab, sos=True, eos=True):\n    in_tensor_list = []\n    out_tensor_list = []\n    for pair in data.values:\n        input_tensor = tensorFromWord(in_vocab, pair[0], sos, eos)\n        output_tensor = tensorFromWord(out_vocab, pair[1], sos, eos)\n        in_tensor_list.append(input_tensor)\n        out_tensor_list.append(output_tensor)\n    in_tensor_pad = pad_sequence(in_tensor_list, padding_value=PAD_idx, batch_first=False)\n    out_tensor_pad = pad_sequence(out_tensor_list, padding_value=PAD_idx, batch_first=False)\n    return in_tensor_pad, out_tensor_pad","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:26:23.959621Z","iopub.execute_input":"2023-05-06T19:26:23.960088Z","iopub.status.idle":"2023-05-06T19:26:23.972251Z","shell.execute_reply.started":"2023-05-06T19:26:23.960050Z","shell.execute_reply":"2023-05-06T19:26:23.971086Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# load dataset\ntrain_data = pd.read_csv('/kaggle/input/eng-hin/hin_train.csv', sep=',', header=None)\ntest_data = pd.read_csv('/kaggle/input/eng-hin/hin_test.csv', sep=',', header=None)\nvalid_data = pd.read_csv('/kaggle/input/eng-hin/hin_valid.csv', sep=',', header=None)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:26:23.974180Z","iopub.execute_input":"2023-05-06T19:26:23.974639Z","iopub.status.idle":"2023-05-06T19:26:24.131511Z","shell.execute_reply.started":"2023-05-06T19:26:23.974594Z","shell.execute_reply":"2023-05-06T19:26:24.130359Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# build vocabulary\nx_vocab, y_vocab = prepareVocab(train_data)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:26:24.133151Z","iopub.execute_input":"2023-05-06T19:26:24.133492Z","iopub.status.idle":"2023-05-06T19:26:24.461888Z","shell.execute_reply.started":"2023-05-06T19:26:24.133460Z","shell.execute_reply":"2023-05-06T19:26:24.460816Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"x_train, y_train = processData(train_data, x_vocab, y_vocab)\nx_test, y_test = processData(test_data, x_vocab, y_vocab)\nx_valid, y_valid = processData(valid_data, x_vocab, y_vocab)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:26:24.463625Z","iopub.execute_input":"2023-05-06T19:26:24.463968Z","iopub.status.idle":"2023-05-06T19:26:26.448217Z","shell.execute_reply.started":"2023-05-06T19:26:24.463937Z","shell.execute_reply":"2023-05-06T19:26:26.447347Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(x_train.size())\nprint(x_test.size())\nprint(x_valid.size())","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:26:26.449884Z","iopub.execute_input":"2023-05-06T19:26:26.450729Z","iopub.status.idle":"2023-05-06T19:26:26.459498Z","shell.execute_reply.started":"2023-05-06T19:26:26.450684Z","shell.execute_reply":"2023-05-06T19:26:26.458146Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"torch.Size([26, 51200])\ntorch.Size([28, 4096])\ntorch.Size([24, 4096])\n","output_type":"stream"}]},{"cell_type":"code","source":"print(y_train.size())\nprint(y_test.size())\nprint(y_valid.size())","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:26:26.461740Z","iopub.execute_input":"2023-05-06T19:26:26.462185Z","iopub.status.idle":"2023-05-06T19:26:26.469915Z","shell.execute_reply.started":"2023-05-06T19:26:26.462143Z","shell.execute_reply":"2023-05-06T19:26:26.468693Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"torch.Size([22, 51200])\ntorch.Size([22, 4096])\ntorch.Size([22, 4096])\n","output_type":"stream"}]},{"cell_type":"code","source":"# print first 5 words from train dataset\nfor i in range(5):\n    x_tensor = x_train[:,i]\n    y_tensor = y_train[:,i]\n    \n    x_word = \"\"\n    y_word = \"\"\n    \n    for idx in x_tensor:\n        if idx >= 3:\n            x_word += x_vocab.index2char[idx.item()]\n    \n    for idx in y_tensor:\n        if idx >= 3:\n            y_word += y_vocab.index2char[idx.item()]\n            \n    print(x_word, y_word)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T19:32:56.840219Z","iopub.execute_input":"2023-05-06T19:32:56.840601Z","iopub.status.idle":"2023-05-06T19:32:56.852449Z","shell.execute_reply.started":"2023-05-06T19:32:56.840570Z","shell.execute_reply":"2023-05-06T19:32:56.851163Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"shastragaar शस्त्रागार\nbindhya बिन्द्या\nkirankant किरणकांत\nyagyopaveet यज्ञोपवीत\nratania रटानिया\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}